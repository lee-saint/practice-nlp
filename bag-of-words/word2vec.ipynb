{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuff going moment mj started listening music ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classic war worlds timothy hines entertaining ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film starts manager nicholas bell giving welco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>must assumed praised film greatest filmed oper...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly trashy wondrously unpretentious explo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  stuff going moment mj started listening music ...          1\n",
       "1  classic war worlds timothy hines entertaining ...          1\n",
       "2  film starts manager nicholas bell giving welco...          0\n",
       "3  must assumed praised film greatest filmed oper...          0\n",
       "4  superbly trashy wondrously unpretentious explo...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in_path = './data_in/'\n",
    "train_clean_data = 'train_clean.csv'\n",
    "\n",
    "train_data = pd.read_csv(data_in_path + train_clean_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary',\n",
       " 'watched',\n",
       " 'wiz',\n",
       " 'watched',\n",
       " 'moonwalker',\n",
       " 'maybe',\n",
       " 'want',\n",
       " 'get',\n",
       " 'certain',\n",
       " 'insight',\n",
       " 'guy',\n",
       " 'thought',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'eighties',\n",
       " 'maybe',\n",
       " 'make',\n",
       " 'mind',\n",
       " 'whether',\n",
       " 'guilty',\n",
       " 'innocent',\n",
       " 'moonwalker',\n",
       " 'part',\n",
       " 'biography',\n",
       " 'part',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'remember',\n",
       " 'going',\n",
       " 'see',\n",
       " 'cinema',\n",
       " 'originally',\n",
       " 'released',\n",
       " 'subtle',\n",
       " 'messages',\n",
       " 'mj',\n",
       " 'feeling',\n",
       " 'towards',\n",
       " 'press',\n",
       " 'also',\n",
       " 'obvious',\n",
       " 'message',\n",
       " 'drugs',\n",
       " 'bad',\n",
       " 'kay',\n",
       " 'visually',\n",
       " 'impressive',\n",
       " 'course',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'unless',\n",
       " 'remotely',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'anyway',\n",
       " 'going',\n",
       " 'hate',\n",
       " 'find',\n",
       " 'boring',\n",
       " 'may',\n",
       " 'call',\n",
       " 'mj',\n",
       " 'egotist',\n",
       " 'consenting',\n",
       " 'making',\n",
       " 'movie',\n",
       " 'mj',\n",
       " 'fans',\n",
       " 'would',\n",
       " 'say',\n",
       " 'made',\n",
       " 'fans',\n",
       " 'true',\n",
       " 'really',\n",
       " 'nice',\n",
       " 'actual',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'bit',\n",
       " 'finally',\n",
       " 'starts',\n",
       " 'minutes',\n",
       " 'excluding',\n",
       " 'smooth',\n",
       " 'criminal',\n",
       " 'sequence',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'convincing',\n",
       " 'psychopathic',\n",
       " 'powerful',\n",
       " 'drug',\n",
       " 'lord',\n",
       " 'wants',\n",
       " 'mj',\n",
       " 'dead',\n",
       " 'bad',\n",
       " 'beyond',\n",
       " 'mj',\n",
       " 'overheard',\n",
       " 'plans',\n",
       " 'nah',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'character',\n",
       " 'ranted',\n",
       " 'wanted',\n",
       " 'people',\n",
       " 'know',\n",
       " 'supplying',\n",
       " 'drugs',\n",
       " 'etc',\n",
       " 'dunno',\n",
       " 'maybe',\n",
       " 'hates',\n",
       " 'mj',\n",
       " 'music',\n",
       " 'lots',\n",
       " 'cool',\n",
       " 'things',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'turning',\n",
       " 'car',\n",
       " 'robot',\n",
       " 'whole',\n",
       " 'speed',\n",
       " 'demon',\n",
       " 'sequence',\n",
       " 'also',\n",
       " 'director',\n",
       " 'must',\n",
       " 'patience',\n",
       " 'saint',\n",
       " 'came',\n",
       " 'filming',\n",
       " 'kiddy',\n",
       " 'bad',\n",
       " 'sequence',\n",
       " 'usually',\n",
       " 'directors',\n",
       " 'hate',\n",
       " 'working',\n",
       " 'one',\n",
       " 'kid',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'whole',\n",
       " 'bunch',\n",
       " 'performing',\n",
       " 'complex',\n",
       " 'dance',\n",
       " 'scene',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movie',\n",
       " 'people',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'one',\n",
       " 'level',\n",
       " 'another',\n",
       " 'think',\n",
       " 'people',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'try',\n",
       " 'give',\n",
       " 'wholesome',\n",
       " 'message',\n",
       " 'ironically',\n",
       " 'mj',\n",
       " 'bestest',\n",
       " 'buddy',\n",
       " 'movie',\n",
       " 'girl',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'truly',\n",
       " 'one',\n",
       " 'talented',\n",
       " 'people',\n",
       " 'ever',\n",
       " 'grace',\n",
       " 'planet',\n",
       " 'guilty',\n",
       " 'well',\n",
       " 'attention',\n",
       " 'gave',\n",
       " 'subject',\n",
       " 'hmmm',\n",
       " 'well',\n",
       " 'know',\n",
       " 'people',\n",
       " 'different',\n",
       " 'behind',\n",
       " 'closed',\n",
       " 'doors',\n",
       " 'know',\n",
       " 'fact',\n",
       " 'either',\n",
       " 'extremely',\n",
       " 'nice',\n",
       " 'stupid',\n",
       " 'guy',\n",
       " 'one',\n",
       " 'sickest',\n",
       " 'liars',\n",
       " 'hope',\n",
       " 'latter']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])\n",
    "\n",
    "sentences = []\n",
    "for review in reviews:\n",
    "    sentences.append(review.split())\n",
    "\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시 필요한 하이퍼파라미터\n",
    "num_features = 300         # 워드 벡터 특징값 수\n",
    "min_word_count = 40        # 단어에 대한 최소 빈도 수\n",
    "num_workers = 4            # 프로세스 개수\n",
    "context = 10               # 컨텍스트 윈도우 크기\n",
    "downsampling = 1e-3        # 다운샘플링 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-21 16:43:21,189: INFO: collecting all words and their counts\n",
      "2020-01-21 16:43:21,192: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-21 16:43:21,398: INFO: PROGRESS: at sentence #10000, processed 1205223 words, keeping 51374 word types\n",
      "2020-01-21 16:43:21,598: INFO: PROGRESS: at sentence #20000, processed 2396605 words, keeping 67660 word types\n",
      "2020-01-21 16:43:21,705: INFO: collected 74065 word types from a corpus of 2988089 raw words and 25000 sentences\n",
      "2020-01-21 16:43:21,706: INFO: Loading a fresh vocabulary\n",
      "2020-01-21 16:43:21,741: INFO: effective_min_count=40 retains 8160 unique words (11% of original 74065, drops 65905)\n",
      "2020-01-21 16:43:21,742: INFO: effective_min_count=40 leaves 2627273 word corpus (87% of original 2988089, drops 360816)\n",
      "2020-01-21 16:43:21,768: INFO: deleting the raw counts dictionary of 74065 items\n",
      "2020-01-21 16:43:21,769: INFO: sample=0.001 downsamples 30 most-common words\n",
      "2020-01-21 16:43:21,770: INFO: downsampling leaves estimated 2494384 word corpus (94.9% of prior 2627273)\n",
      "2020-01-21 16:43:21,791: INFO: estimated required memory for 8160 words and 300 dimensions: 23664000 bytes\n",
      "2020-01-21 16:43:21,793: INFO: resetting layer weights\n",
      "2020-01-21 16:43:23,217: INFO: training model with 4 workers on 8160 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-01-21 16:43:24,235: INFO: EPOCH 1 - PROGRESS: at 43.41% examples, 1077003 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-21 16:43:25,249: INFO: EPOCH 1 - PROGRESS: at 92.40% examples, 1139032 words/s, in_qsize 8, out_qsize 0\n",
      "2020-01-21 16:43:25,378: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-21 16:43:25,380: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-21 16:43:25,383: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-21 16:43:25,389: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-21 16:43:25,390: INFO: EPOCH - 1 : training on 2988089 raw words (2494779 effective words) took 2.2s, 1149992 effective words/s\n",
      "2020-01-21 16:43:26,398: INFO: EPOCH 2 - PROGRESS: at 49.37% examples, 1235532 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-21 16:43:27,370: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-21 16:43:27,379: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-21 16:43:27,380: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-21 16:43:27,385: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-21 16:43:27,386: INFO: EPOCH - 2 : training on 2988089 raw words (2494327 effective words) took 2.0s, 1251627 effective words/s\n",
      "2020-01-21 16:43:28,392: INFO: EPOCH 3 - PROGRESS: at 50.00% examples, 1257578 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-21 16:43:29,349: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-21 16:43:29,359: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-21 16:43:29,364: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-21 16:43:29,367: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-21 16:43:29,368: INFO: EPOCH - 3 : training on 2988089 raw words (2494441 effective words) took 2.0s, 1262186 effective words/s\n",
      "2020-01-21 16:43:30,373: INFO: EPOCH 4 - PROGRESS: at 50.69% examples, 1272700 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-21 16:43:31,289: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-21 16:43:31,297: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-21 16:43:31,301: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-21 16:43:31,310: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-21 16:43:31,311: INFO: EPOCH - 4 : training on 2988089 raw words (2494648 effective words) took 1.9s, 1286480 effective words/s\n",
      "2020-01-21 16:43:32,316: INFO: EPOCH 5 - PROGRESS: at 49.36% examples, 1239845 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-21 16:43:33,318: INFO: EPOCH 5 - PROGRESS: at 97.78% examples, 1219218 words/s, in_qsize 7, out_qsize 0\n",
      "2020-01-21 16:43:33,346: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-01-21 16:43:33,352: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-01-21 16:43:33,363: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-01-21 16:43:33,371: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-01-21 16:43:33,373: INFO: EPOCH - 5 : training on 2988089 raw words (2494390 effective words) took 2.1s, 1212037 effective words/s\n",
      "2020-01-21 16:43:33,373: INFO: training on a 14940445 raw words (12472585 effective words) took 10.2s, 1227973 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "print('Training model...')\n",
    "model = word2vec.Word2Vec(sentences,\n",
    "                         workers=num_workers,\n",
    "                         size=num_features,\n",
    "                         min_count=min_word_count,\n",
    "                         window=context,\n",
    "                         sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-21 16:44:47,258: INFO: saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2020-01-21 16:44:47,260: INFO: not storing attribute vectors_norm\n",
      "2020-01-21 16:44:47,260: INFO: not storing attribute cum_table\n",
      "2020-01-21 16:44:47,436: INFO: saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "model_name = '300features_40minwords_10context'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words, model, num_features):\n",
    "    # 출력 벡터 초기화\n",
    "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
    "    \n",
    "    num_words = 0\n",
    "    # 어휘사전 준비\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words += 1\n",
    "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "    \n",
    "    # 문장의 단어 수만큼 나누어 단어 벡터의 평균값을 문장 벡터로 함\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features):\n",
    "    dataset = list()\n",
    "    \n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "        \n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "test_data_vecs = get_dataset(sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습과 검증 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 300) (20000,)\n",
      "(5000, 300) (5000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = test_data_vecs\n",
    "y = np.array(sentiments)\n",
    "\n",
    "random_seed = 42\n",
    "test_split = 0.2\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=test_split, random_state=random_seed)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_eval.shape, y_eval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 선언 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증 데이터셋을 이용한 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8644\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', lgs.score(X_eval, y_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naturally film main themes mortality nostalgia...</td>\n",
       "      <td>12311_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie disaster within disaster film full great...</td>\n",
       "      <td>8348_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie kids saw tonight child loved one point k...</td>\n",
       "      <td>5828_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afraid dark left impression several different ...</td>\n",
       "      <td>7186_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accurate depiction small time mob life filmed ...</td>\n",
       "      <td>12128_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review        id\n",
       "0  naturally film main themes mortality nostalgia...  12311_10\n",
       "1  movie disaster within disaster film full great...    8348_2\n",
       "2  movie kids saw tonight child loved one point k...    5828_4\n",
       "3  afraid dark left impression several different ...    7186_2\n",
       "4  accurate depiction small time mob life filmed ...   12128_7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean_data = 'test_clean.csv'\n",
    "\n",
    "test_data = pd.read_csv(data_in_path + test_clean_data, header=0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = list(test_data['review'])\n",
    "\n",
    "test_sentences = []\n",
    "for review in test_review:\n",
    "    test_sentences.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "test_data_vecs = get_dataset(test_sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_out_path = './data_out/'\n",
    "\n",
    "test_predicted = lgs.predict(test_data_vecs)\n",
    "\n",
    "if not os.path.exists(data_out_path):\n",
    "    os.makedirs(data_out_path)\n",
    "    \n",
    "ids = list(test_data['id'])\n",
    "answer_dataset = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'sentiment': test_predicted\n",
    "})\n",
    "answer_dataset.to_csv(data_out_path + 'lgs_answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
